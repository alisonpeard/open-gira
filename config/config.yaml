# Input data and output locations
output_dir: 'results'


#####################################
### FLOODING / TRANSPORT WORKFLOW ###
#####################################


## Aqueduct Analysis ##
# This should be a named list of files that specify hazard raster files
# to retrieve using wget -i
hazard_datasets:
  aqueduct-coast: 'https://raw.githubusercontent.com/mjaquiery/aqueduct/main/tiffs.txt'
  aqueduct-river: 'config/hazard_resource_locations/aqueduct_river_rcp4p5_MIROC-ESM-CHEM_2030_tifs.txt'  # subset of aqueduct_tifs.txt

# OSM datasets, principally from: https://download.geofabrik.de/ #
infrastructure_datasets:
  europe-latest: 'https://download.geofabrik.de/europe-latest.osm.pbf'
  wales-latest: 'https://download.geofabrik.de/europe/great-britain/wales-latest.osm.pbf'
  africa-latest: 'http://download.geofabrik.de/africa-latest.osm.pbf'
  egypt-latest: 'http://download.geofabrik.de/africa/egypt-latest.osm.pbf'
  kenya-latest: 'http://download.geofabrik.de/africa/kenya-latest.osm.pbf'
  tanzania-latest: 'https://download.geofabrik.de/africa/tanzania-latest.osm.pbf'
  tanzania-mini: 'https://raw.githubusercontent.com/mjaquiery/aqueduct/main/tanzania-mini.osm.pbf'

# these files contain osmium filter expressions for selecting relevant nodes, ways and relations from .osm.pbf files
# the keys in the mapping, i.e. 'road' and 'rail' will be used to create FILTER_SLUG in rules
network_filters:
  road: 'config/osm_filters/road-tertiary.txt'
  rail: 'config/osm_filters/rail.txt'

# OSM tag data to retain on selected features, typically for usage in network annotation/analysis
# N.B. feature SELECTION is done with the expressions pointed to from network_filters
keep_tags:
  road: ['highway', 'surface', 'bridge', 'maxspeed', 'lanes']
  rail: ['railway', 'bridge', 'name']

# Number of slices to cut dataset into -- must be a square number
slice_count: 9

# CRS OSM uses
osm_epsg: 4326

transport:
  # if the following data can be sourced/hosted online, remove these config entries and download instead
  rehabilitation_costs_path: 'bundled_data/transport/rehabilitation.xlsx'
  tariff_costs_path: 'bundled_data/transport/tariffs.xlsx'
  speeds_path: 'bundled_data/transport/speeds.xlsx'
  road:
    # road network specific configuration
    default_shoulder_width_metres: 1.5
    default_lane_width_metres: 3.25
    # fudge factor to tune flow allocation
    flow_cost_time_factor: 0.49
  rail:
    flow_cost_time_factor: 0.49


###############################
### STORM / ENERGY WORKFLOW ###
###############################


# Options for exposure tif file generation
exposure_tifs:
  # When generating exposure summaries, filter by cells with at >= exposure_threshold m of flooding
  exposure_threshold: 0.5
  # Used when scaling raster files, values < 1 will downsample
  scaling_factor: 0.1
  # Used to determine how resampling occurs. Valid values are in rasterio.enums.Resampling.
  resampling_mode: 'bilinear'
  # Options for plotting
  plot:
    # Keyword arguments for raster plotting
    raster:
      # Colour mapping to use for raster data
      cmap: 'Reds'

## STORM Power Network Analysis ##
# Storm model type. Options: constant (no climate effects), CMCC-CM2-VHR4, CNRM-CM6-1-HR, EC-Earth3P-HR, HadGEM3-GC31-HM.
storm_model_type: 'constant'

# Failure threshold central value m/s. This value is the threshold at which the network assets are expected to fail based on available literature. The recommended setting is 40 m/s
central_threshold: 35

# Minimum failure threshold value m/s. This is the lowest expected value for failure to account for uncertainty in central_threshold
minimum_threshold: 20

# Maxmimum failure threshold value m/s. This is the highest expected value for failure to account for uncertainty in central_threshold
maximum_threshold: 50

# Width and height of dataset-splitting box (must be factor of 180)
box_width_height: 5

# List of boxes NUMBERS to analyse (only) e.g. [1029, 1028, 1030, 957].
# Note that this must be known for the box_width_height value entered above.
# use an empty list to evaluate globally
specific_boxes: []
# this contains Puerto Rico (direct hit for Hurricane Maria of 2017)
# specific_boxes: [1030]
# box IDs for the Caribbean on a 5 degree grid, east to west, south to north
# specific_boxes: [1103, 1032, 1030, 1029, 957, 1028, 956, 884, 955, 883]

# STORM BASINS #
# Tropical cyclone basins to analyse. List of strings.
# Empty list for global analysis.
# Options: "EP", "NA", "NI", "SI", "SP", "WP".
# If `specific_boxes` are selected, this must be coherent with `storm_basins`
storm_basins: []

# SAMPLES #
# storm datasets are split into 'samples', each comprising 1,000 years of storm data
# typically there are 10 samples available for each model
# to use all available samples, specify an empty list
storm_files_sample_set: [0]

# Direct damage cost per km (USD) for high voltage lines. 400 000USD suggestion for upper limit
reconstruction_cost_high: 400000

# Direct damage cost per km (USD) for low and medium voltage lines. XXX 000USD suggestion for upper limit
reconstruction_cost_lowmedium: 200000

# Further Configuration #
# Storms will be analysed in batches of this value. Higher value: quicker process. Lower value: better memory. It is recommended to tweak this value dependent on the machine's available memory and/or user requirements (500 is often a good starting value). Note that at below 25, attempts are made to record which files store which data as to only load the relevant wind csv files. This may explain increases/decreases in performance.
storm_batches: 900

# If set to True then wind_extracter will overwrite existing wind files. It is recommended to keep this as False unless changes are made in the wind configuration files/scripts.
wind_rerun: True

# Analysis #
# Percentage of storms to select for geospatial analysis and visualisation. Set to 100 for all
top_select: 100

# Set increasing severity for top_select. True means top_select is the first top_select% of storms in increasing severity (i.e. first one is the least damaging storm). False means the top top_select% worst storms are analysed (i.e. first on is the most damaging storm)
increased_severity_sort: True

# Percentile select
percentile: 99

# Spatial level to aggregate to for geospatial analyses (0 = country and up to 5 inclusive). The higher the number the longer the processing
aggregate_level: 1

# Specific storms to analyse in analyse_all workflow. In form of list of strings [#_#_#, #_#_#,... ]. Write None to include all
specific_storm_analysis: ['99_2017_0']
