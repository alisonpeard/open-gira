{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c6c070",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Validation of open-gira power outage model\n",
    "This notebook compares modelled and observed customer disconnected estimates\n",
    "Observed data are collated media and goverment reports (CSV files in validation/)\n",
    "Modelled data are exposure_by_country.nc for the whole IBTrACS storm set\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6b87f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be058577",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69837a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model outputs\n",
    "root_path = \"/home/fred/projects/open_gira/open-gira/\"\n",
    "tracks_path = os.path.join(root_path, \"results/input/IBTrACS/processed/v4.geoparquet\")\n",
    "targets_path = os.path.join(root_path, \"results/power/targets_with_iso_a3.geoparquet\")\n",
    "exposure_path = os.path.join(root_path, \"results/power/by_storm_set/IBTrACS/exposure_by_country.nc\")\n",
    "\n",
    "# validation data\n",
    "# https://www.un.org/development/desa/pd/data/household-size-and-composition\n",
    "household_path = os.path.join(root_path, \"undesa_pd_2022_hh-size-composition.xlsx\")\n",
    "# https://gist.githubusercontent.com/tadast/8827699/raw/f5cac3d42d16b78348610fc4ec301e9234f82821/countries_codes_and_coordinates.csv\n",
    "iso_codes = os.path.join(root_path, \"iso_codes.csv\")\n",
    "# see source column\n",
    "outage_paths = glob(os.path.join(root_path, \"validation/observed_outages/*.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37b9522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read iso numeric to alpha table\n",
    "rename_dict = {\n",
    "    \"Country\": \"name\",\n",
    "    \"Alpha-2 code\": \"iso_a2\",\n",
    "    \"Alpha-3 code\": \"iso_a3\",\n",
    "    \"Numeric code\": \"iso_num\"\n",
    "}\n",
    "iso = pd.read_csv(iso_codes, usecols=rename_dict.keys())\n",
    "iso = iso.rename(columns=rename_dict)\n",
    "# strip out quotes\n",
    "for c in iso.columns:\n",
    "    iso[c] = iso[c].str.replace('\"', \"\").str.strip()\n",
    "iso.iso_num = iso.iso_num.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9551117c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read household size data\n",
    "rename_dict = {\n",
    "    \"ISO Code\": \"iso_num\",\n",
    "    \"Reference date (dd/mm/yyyy)\": \"ref_date\",\n",
    "    \"Average household size (number of members)\": \"mean_household_pop\"\n",
    "}\n",
    "hh = pd.read_excel(household_path, sheet_name=\"HH size and composition 2022\", header=4, usecols=rename_dict.keys())\n",
    "hh = hh.rename(columns=rename_dict)\n",
    "hh.ref_date = pd.to_datetime(hh.ref_date, dayfirst=True)\n",
    "\n",
    "# any non-numeric value -> NaN (some '..' placeholders in excel data)\n",
    "hh[\"mean_household_pop\"] = pd.to_numeric(hh[\"mean_household_pop\"], errors=\"coerce\")\n",
    "\n",
    "# drop any rows without a valid mean household pop\n",
    "hh = hh[~hh.mean_household_pop.isna()]\n",
    "\n",
    "# discard all but most recent entry for each territory\n",
    "hh = hh.sort_values([\"ref_date\"], ascending=False).drop_duplicates(\"iso_num\", keep=\"first\")\n",
    "\n",
    "# merge in iso alpha ids (will permit join with outage data)\n",
    "hh = hh.merge(iso, how=\"left\", on=\"iso_num\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ae7771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now compare population_affected with the exposure_by_country.nc data\n",
    "ds = xr.open_dataset(exposure_path).rename({\"country\": \"country_iso_a3\"})\n",
    "\n",
    "by_threshold = {}\n",
    "for threshold in ds.threshold.values:\n",
    "\n",
    "    # storm loop\n",
    "    obs_data = {os.path.basename(p).split(\".\")[0]: pd.read_csv(p) for p in sorted(outage_paths)}\n",
    "    by_storm = {}\n",
    "    for event_id, obs in obs_data.items():\n",
    "        \n",
    "        try:\n",
    "            # select model data for given storm and threshold\n",
    "            mod = ds.customers_affected.sel(dict(event_id=event_id, threshold=threshold)).to_pandas()\n",
    "        except KeyError:\n",
    "            # storm has no modelled results for any threshold\n",
    "            continue\n",
    "        \n",
    "        # create a duplicate dataframe for modelled and derived measures (as well as obs)\n",
    "        by_storm[event_id] = obs.copy()\n",
    "        \n",
    "        # bring in demographic data to obs dataframe\n",
    "        obs = obs.rename(columns={\"country_iso_a3\": \"iso_a3\"}).merge(hh, how=\"left\", on=\"iso_a3\")\n",
    "\n",
    "        for i in range(len(obs)):\n",
    "            # gap-fill the population_affected numbers where we have customers_affected only\n",
    "            if pd.isna(obs.loc[i, \"population_affected\"]):\n",
    "                by_storm[event_id].loc[i, \"population_affected\"] = \\\n",
    "                    obs.loc[i, \"customers_affected\"] * obs.loc[i, \"mean_household_pop\"]\n",
    "\n",
    "        # take the largest estimate for each country (we assume reports underestimate outages)\n",
    "        by_storm[event_id] = by_storm[event_id].groupby(\"country_iso_a3\").max()\n",
    "        by_storm[event_id] = by_storm[event_id][[\"population_affected\"]]\n",
    "        by_storm[event_id] = by_storm[event_id].rename(columns={\"population_affected\": \"observed\"})\n",
    "\n",
    "        # modelled customers_affected (really population affected, should change this name!)\n",
    "        mod.name = \"modelled\"\n",
    "        by_storm[event_id] = by_storm[event_id].join(mod)\n",
    "        by_storm[event_id][\"error\"] = \\\n",
    "            by_storm[event_id].modelled - by_storm[event_id].observed\n",
    "        by_storm[event_id][\"error_abs\"] = \\\n",
    "            np.abs(by_storm[event_id][\"error\"])\n",
    "        by_storm[event_id][\"ratio\"] = \\\n",
    "            by_storm[event_id].modelled / by_storm[event_id].observed\n",
    "        by_storm[event_id][\"error_norm\"] = \\\n",
    "            by_storm[event_id].error / by_storm[event_id].observed\n",
    "        by_storm[event_id][\"signed_ratio\"] = \\\n",
    "            np.sign(by_storm[event_id].error) * by_storm[event_id].ratio\n",
    "\n",
    "    concat = pd.concat(by_storm)\n",
    "    concat.index.names = [\"event_id\", \"country_iso_a3\"]\n",
    "    by_threshold[threshold] = concat\n",
    "\n",
    "# all data with a 3 level multi-index\n",
    "data = pd.concat(by_threshold, names=[\"threshold\", \"event_id\", \"country_iso_a3\"])\n",
    "\n",
    "# write to disk\n",
    "data.to_csv(\"outage_model_validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae309c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example data for a given threshold\n",
    "data.loc[32.5, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd567148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# where are these tracks?\n",
    "borders = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))\n",
    "tracks = gpd.read_parquet(tracks_path)\n",
    "tracks = tracks[tracks.track_id.isin(set(data.index.get_level_values(\"event_id\")))]\n",
    "\n",
    "f, ax = plt.subplots(figsize=(16, 7))\n",
    "\n",
    "# plot landmasses and political borders\n",
    "borders.plot(ax=ax, facecolor=\"none\", edgecolor=\"grey\", alpha=0.5)\n",
    "\n",
    "# plot tracks with colourbar for wind speed intensity\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.15)\n",
    "markersize = np.exp(tracks.category)\n",
    "tracks.plot(column=\"max_wind_speed_ms\", ax=ax, s=markersize, cax=cax, legend=True, cmap=\"viridis\")\n",
    "cax.set_ylabel(\"Max wind speed $[ms^{-1}]$\")\n",
    "\n",
    "ax.set_xlim(-130, 180)\n",
    "ax.set_ylim(-60, 75)\n",
    "ax.set_title(\"Tracks of storms with observed outage data\")\n",
    "ax.set_xlabel(\"Longitude [deg]\")\n",
    "ax.set_ylabel(\"Latitude [deg]\")\n",
    "\n",
    "# second legend for saffir simpson storm classification\n",
    "saffir_simpson = ax.legend(\n",
    "    handles=[\n",
    "        Line2D(\n",
    "            [],\n",
    "            [],\n",
    "            color=plt.get_cmap(\"viridis\")(0.8),\n",
    "            lw=0,\n",
    "            marker=\"o\",\n",
    "            markersize=np.sqrt(b),\n",
    "            label=np.log(b),\n",
    "        )\n",
    "        for b in sorted(set(markersize))\n",
    "    ],\n",
    "    loc=\"lower left\",\n",
    "    title=\"Saffir-Simpson scale\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75841142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_cmap(cmap_name: str, categories: list) -> dict[str: tuple[float]]:\n",
    "    scalar_mappable = matplotlib.cm.ScalarMappable(matplotlib.colors.Normalize(0, 1), cmap_name)\n",
    "    return {code: scalar_mappable.to_rgba(i / len(categories)) for i, code in enumerate(categories)}\n",
    "\n",
    "# create some colourmaps and persist between plots\n",
    "\n",
    "# make a country colormap\n",
    "countries = sorted(set(data.index.get_level_values(\"country_iso_a3\").values))\n",
    "country_cmap = categorical_cmap(\"tab20c\", countries)\n",
    "\n",
    "# make a cmap for wind speed thresholds\n",
    "thresholds = sorted(set(data.index.get_level_values(\"threshold\").values))\n",
    "wind_cmap = categorical_cmap(\"plasma\", thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daa83eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot modelled vs. observed by threshold\n",
    "\n",
    "n = len(thresholds)\n",
    "ncols = min([n, 4])\n",
    "nrows = (n // ncols) + (n % ncols)\n",
    "f, axes = plt.subplots(ncols=ncols, nrows=nrows, figsize=(3 + 2.5 * ncols, 2 + 2 * nrows), squeeze=False)\n",
    "\n",
    "for row in range(nrows):\n",
    "    for col in range(ncols):\n",
    "\n",
    "        i = col + (row * ncols)\n",
    "        ax = axes[row, col]\n",
    "        \n",
    "        if i < n:\n",
    "            threshold = thresholds[i]\n",
    "            df = data.loc[threshold, :, :]\n",
    "\n",
    "            # build a list of RGBA values the same length as the data\n",
    "            colours = [country_cmap[value] for value in df.index.get_level_values(\"country_iso_a3\").values]\n",
    "\n",
    "            ax.scatter(df.observed, df.modelled, marker=\"x\", c=colours)\n",
    "            x = np.linspace(0, 10 * max(df.observed), 100)\n",
    "            ax.plot(x, x, ls=\"--\", c=\"cornflowerblue\")\n",
    "            ax.grid()\n",
    "            ax.set_title(f\"$s_{{th}} = {threshold} \\ m s^{{-1}}$\", size=10)\n",
    "            ax.set_xscale(\"log\")\n",
    "            ax.set_yscale(\"log\")\n",
    "            ax.set_xlim(1E5, 1E8)\n",
    "            ax.set_ylim(1E5, 1E8)\n",
    "\n",
    "        # disable any axes we don't need\n",
    "        else:\n",
    "            ax.set_axis_off()\n",
    "\n",
    "handles = [\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor=v, label=k, markersize=8)\n",
    "    for k, v in country_cmap.items() if isinstance(k, str)\n",
    "]\n",
    "f.legend(handles=handles, ncol=1, bbox_to_anchor=(0.95, 0.92), fontsize=9)\n",
    "    \n",
    "f.supxlabel(\"Observed pop. disconnected, $p_{d,obs}$\")\n",
    "f.supylabel(\"Modelled pop. disconnected, $p_{d,mod}$\")\n",
    "f.suptitle(\"Population disconnected, $p_{d}(s_{th})$\")\n",
    "\n",
    "plt.subplots_adjust(bottom=0.11, top=0.88, left=0.08, right=0.9, hspace=0.35, wspace=0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1197bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot modelled vs. observed by threshold (same plot)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(6, 6))\n",
    "    \n",
    "for threshold in thresholds:\n",
    "    df = data.loc[threshold, :, :]\n",
    "    ax.scatter(df.observed, df.modelled, marker=\"x\", label=threshold, color=wind_cmap[threshold])\n",
    "    \n",
    "x = np.linspace(0, 10 * max(data.observed), 100)\n",
    "ax.plot(x, x, ls=\"--\", c=\"cornflowerblue\")\n",
    "ax.grid()\n",
    "ax.set_title(\"Population disconnected, $p_{d}(s_{th})$\")\n",
    "ax.set_xlabel(\"Observed pop. disconnected, $p_{d,obs}$\")\n",
    "ax.set_ylabel(\"Modelled pop. disconnected, $p_{d,mod}$\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xlim(1E4, 1E8)\n",
    "ax.set_ylim(1E4, 1E8)\n",
    "ax.legend(title=\"Wind speed\\n threshold,\\n$s_{th}$, $[m s^{{-1}}]$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5442f06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot normalised residual as a function of threshold\n",
    "\n",
    "df = data[\"error_norm\"].reset_index([\"threshold\", \"country_iso_a3\"])\n",
    "colours = [country_cmap[value] for value in df.country_iso_a3.values]\n",
    "\n",
    "f, ax = plt.subplots(figsize=(8,6))\n",
    "ax.scatter(df.threshold, df.error_norm, c=colours, label=\"Country\", marker=\"x\")\n",
    "handles = [Line2D([0], [0], marker='o', color='w', markerfacecolor=v, label=k, markersize=8) for k, v in country_cmap.items() if isinstance(k, str)]\n",
    "ax.legend(title='Country', handles=handles, fontsize=9, loc=\"upper right\")\n",
    "ax.grid()\n",
    "ax.axhline(0, ls=\"--\", c=\"cornflowerblue\")\n",
    "ax.set_xlabel(r\"Wind speed threshold, $s_{th}$, $[m s^{-1}]$\")\n",
    "ax.set_ylabel(r\"Normalised residual, $\\mathrm{\\frac{p_{d,mod} - p_{d,obs}}{p_{d,obs}}}$\")\n",
    "ax.set_title(\"Population disconnected, $p_{d}(s_{th})$, residuals\")\n",
    "ax.set_ylim(-1.5, 4)\n",
    "\n",
    "plt.subplots_adjust(right=0.8)\n",
    "\n",
    "# N.B. a couple of values are more more than 400% out, therefore out of plot area\n",
    "# -1, worst possible score (model 100% underestimated)\n",
    "# 0, perfect score\n",
    "# + valued, progressively greater model overestimate\n",
    "\n",
    "# N.B. our residuals, i.e. (mod - obs) / obs are not symmetric about 0 (-1 is the worst possible score)\n",
    "# but we plot this measure as a) it's normalised, so can compare across scales\n",
    "# and b) something like sign(mod - obs) * mod / obs, would give a perfect 0 for mod = 0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3130db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as above, but only plot each storm-country pair once, at the threshold with minimum absolute error\n",
    "\n",
    "measure = \"error_norm\"\n",
    "\n",
    "results = []\n",
    "for event_iso, df in data.groupby([\"event_id\", \"country_iso_a3\"]):\n",
    "    min_error_mask = df.error_abs == df.error_abs.min()\n",
    "    try:\n",
    "        # only store the threshold, error pair if there's only a single minima\n",
    "        threshold, = df[min_error_mask].index.get_level_values(\"threshold\")\n",
    "        statistic, = df.loc[min_error_mask, measure]\n",
    "        results.append((threshold, *event_iso, statistic))\n",
    "    except ValueError:\n",
    "        continue\n",
    "        \n",
    "df = pd.DataFrame(results, columns=[\"threshold\", \"event_id\", \"country_iso_a3\", measure])\n",
    "\n",
    "f, ax = plt.subplots(figsize=(6,4))\n",
    "ax.scatter(\n",
    "    df.threshold,\n",
    "    df.error_norm,\n",
    "    c=[country_cmap[value] for value in df.country_iso_a3]\n",
    ")\n",
    "ax.set_ylabel(r\"Normalised residual, $\\mathrm{\\frac{p_{d,mod}(s_{th}) - p_{d,obs}}{p_{d,obs}}}$\")\n",
    "ax.set_xlabel(r\"Wind speed threshold, $s_{th}$, $[m s^{-1}]$\")\n",
    "ax.set_title(\"Population disconnected, $p_{d}$, residuals,\\nfor threshold, $s_{th}$, with $min(abs(p_{d,mod}-p_{d,obs}))$\")\n",
    "ax.set_ylim(-1.1, 1)\n",
    "ax.set_xticks(thresholds)\n",
    "ax.grid()\n",
    "handles = [\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor=v, label=k, markersize=8)\n",
    "    for k, v in country_cmap.items() if isinstance(k, str)\n",
    "]\n",
    "ax.legend(handles=handles, ncol=int(len(handles) / 2), fontsize=7, loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ba11bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_residual_distribution_by_threshold(*, measure: str, x_label: str, x_min: float, x_max: float, bin_width: float, target: float = None):\n",
    "    n = len(thresholds)\n",
    "    ncols = min([n, 4])\n",
    "    nrows = (n // ncols) + (n % ncols)\n",
    "    f, axes = plt.subplots(ncols=ncols, nrows=nrows, figsize=(3 + 2.5 * ncols, 2 + 2.25 * nrows), squeeze=False)\n",
    "    \n",
    "    n_bins = int((x_max - x_min) / bin_width + 1)\n",
    "    bins = np.linspace(x_min, x_max, n_bins)\n",
    "\n",
    "    max_ylim = 0\n",
    "    for row in range(nrows):\n",
    "        for col in range(ncols):\n",
    "\n",
    "            i = col + (row * ncols)\n",
    "            ax = axes[row, col]\n",
    "            if i < n:\n",
    "                threshold = thresholds[i]\n",
    "                residual = data.loc[threshold, :, :][measure]\n",
    "\n",
    "                ax.grid()\n",
    "\n",
    "                # distribution\n",
    "                ax.hist(\n",
    "                    residual,\n",
    "                    bins=bins,\n",
    "                    alpha=0.5,\n",
    "                    label=\"Dist.\",\n",
    "                    facecolor=wind_cmap[threshold]\n",
    "                )\n",
    "\n",
    "                # rug plot\n",
    "                ax.plot(residual, np.zeros(len(residual)), 'b|', ms=15, alpha=0.5, label=\"Data\")\n",
    "\n",
    "                # average measures\n",
    "                mean = np.nanmean(residual)\n",
    "                median = np.nanmedian(residual)\n",
    "                ax.axvline(median, ls=\"--\", c=\"red\", label=r\"$p_{50}$\")\n",
    "                ax.axvline(mean, ls=\"-\", c=\"green\", label=r\"$\\mu$\")\n",
    "\n",
    "                # target\n",
    "                if target is not None:\n",
    "                    ax.axvline(0, ls=\"--\", c=\"cornflowerblue\", label=\"Target\")\n",
    "\n",
    "                ax.set_xlim(x_min, x_max)\n",
    "                _, max_y = ax.get_ylim()\n",
    "                max_ylim = max([max_ylim, max_y])\n",
    "\n",
    "                ax.set_title(f\"$s_{{th}} = {threshold} \\ m s^{{-1}}$\", size=10)\n",
    "                props = dict(boxstyle='round', facecolor='wheat', alpha=0.35)\n",
    "                ax.text(\n",
    "                    0.95,\n",
    "                    0.95,\n",
    "                    \"\\n\".join([f\"$p_{{50}}$ = {median:.2f}\", f\"$\\mu$ = {mean:.2f}\"]),\n",
    "                    transform=ax.transAxes,\n",
    "                    fontsize=8,\n",
    "                    verticalalignment='top',\n",
    "                    horizontalalignment='right',\n",
    "                    bbox=props\n",
    "                )\n",
    "\n",
    "            # disable any axes we don't need\n",
    "            else:\n",
    "                ax.set_axis_off()\n",
    "\n",
    "    # set a common y range for all subplots\n",
    "    for row in range(nrows):\n",
    "        for col in range(ncols):\n",
    "            i = col + (row * ncols)\n",
    "            ax = axes[row, col]\n",
    "            if i < n:\n",
    "                ax.set_ylim(0, max_ylim)\n",
    "\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    f.legend(by_label.values(), by_label.keys(), ncol=5, bbox_to_anchor=(0.68, 0.93))\n",
    "\n",
    "    f.supxlabel(x_label)\n",
    "    f.supylabel(\"Frequency\")\n",
    "    f.suptitle(\"Population disconnected, $p_{d}(s_{th})$, residuals\")\n",
    "\n",
    "    plt.subplots_adjust(bottom=0.1, top=0.82, left=0.08, right=0.87, hspace=0.3, wspace=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84279603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot residual distributions by threshold\n",
    "plot_residual_distribution_by_threshold(\n",
    "    measure=\"error_norm\",\n",
    "    x_label=r\"Normalised residual, $\\mathrm{\\frac{p_{d,mod} - p_{d,obs}}{p_{d,obs}}}$\",\n",
    "    x_min=-1,\n",
    "    x_max=4,\n",
    "    bin_width=2/5,\n",
    "    target=0\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
