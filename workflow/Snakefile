"""
Snakemake file for open-gira.

Snakemake is a workflow organiser. Snakemake is given a list of desired output files
(see rule all below), and if those files don't exist (or aren't up to date), for each
of those files it looks for a rule that can be used to generate it. The process is
then repeated for that rule -- if the files required to build _these files_ don't exist,
look for a rule that will produce them -- and so on.

The Snakemake workflow is covered in detail in the documentation.
"""

import math
import os.path
from glob import glob

import requests

from open_gira.assets import Assets


configfile: "config/config.yaml"

# Check configfile
if any(["/" in h for h in config['hazard_datasets'].keys()]):
    raise ValueError("""Error in config: Hazard dataset names cannot contain / or _""")
if any(["/" in h for h in config['network_filters'].keys()]):
    raise ValueError("""Error in config: Network filter names cannot contain / or _""")
if any(["/" in h for h in config['infrastructure_datasets'].keys()]):
    raise ValueError("""Error in config: Infrastructure dataset names cannot contain / or _""")

# Number of slices to cut dataset into -- must be a square number
if not isinstance(config['slice_count'], int) or \
        (math.sqrt(config['slice_count']) % 1 > 0 and config['slice_count'] != 1):
    raise ValueError("""Error in config: slice_count must be an integer, either a square number or 1""")

n_proc = config["processes_per_parallel_job"]
if not isinstance(n_proc, int) or (n_proc < 1):
    raise ValueError(
        f"config.processes_per_parallel_job has type: {type(n_proc)} and value: {n_proc}, but must be a positive integer"
    )

for network, file_path in config['network_filters'].items():
    if not os.path.exists(file_path):
        raise FileNotFoundError((
            "Error in config: could not locate network_filter at "
            f"{os.path.join(os.getcwd(), file_path)}"
        ))

if len(config["hazard_datasets"].keys()) != len(config["hazard_types"].keys()):
    raise ValueError(f"{config['hazard_datasets']=} not the same length as {config['hazard_types']=}")

permitted_hazard_types = {"flood"}
configured_hazard_types = set(config["hazard_types"].values())
if not configured_hazard_types.issubset(permitted_hazard_types):
    raise ValueError(f"unsupported hazard types: {permitted_hazard_types - configured_hazard_types}")

# check requested direct damage asset types
requested_asset_damage_types = set(config['direct_damages']['asset_types'])
if len(requested_asset_damage_types) == 0:
    # if we were passed an empty list, mutate the config to use all available
    # asset types for direct damage calculation
    config['direct_damages']['asset_types'] = Assets.implemented_assets()
else:
    # if we have a non-empty list, check the request against what's implemented
    # will raise ValueError in case of mismatch
    Assets.valid_selection(requested_asset_damage_types)

# Constrain wildcards to NOT use _ or /
wildcard_constraints:
    DATASET="[^_/]+",
    SLICE_SLUG="slice-[0-9]+",
    FILTER_SLUG="filter-[^_/]+",
    HAZARD_SLUG="hazard-[^_/]+",
    ADMIN_SLUG="admin-level-[0-4]",
    AGG_FUNC_SLUG="agg-sum",
    FILENAME="[^/]+",
    STORM_BASIN="EP|NA|NI|SI|SP|WP",
    STORM_RP="[0-9]+",
    STORM_MODEL="constant|CMCC-CM2-VHR4|CNRM-CM6-1-HR|EC-Earth3P-HR|HadGEM3-GC31-HM",
    STORM_MODEL_FUTURE="CMCC-CM2-VHR4|CNRM-CM6-1-HR|EC-Earth3P-HR|HadGEM3-GC31-HM",
    STORM_SET="(?:IBTrACS|STORM)[^\/]*",
    EVENTS_OR_FIXED="events|fixed",
    DIRECT_DAMAGE_TYPES="fraction_per_RP|cost_per_RP|EAD|EAD_and_cost_per_RP",
    SAMPLE="\d+",
    # may be upper or lower, one 'f' or two
    TIFF_FILE="[^\/\.\s]+\.[tT][iI][fF][fF]?",

# generate values for global variables used across rules
include: "rules/storm_workflow_global_variables.smk"

##### load rules #####
include: "rules/download/coastlines.smk"
include: "rules/download/natural-earth.smk"
include: "rules/download/STORM.smk"
include: "rules/download/IRIS.smk"
include: "rules/download/IBTrACS.smk"
include: "rules/download/gadm.smk"
include: "rules/download/gridfinder.smk"
include: "rules/download/worldpop-population.smk"
include: "rules/download/ghsl-pop.smk"
include: "rules/download/hazards.smk"
include: "rules/download/dryad-gdp.smk"
include: "rules/download/wri-powerplants.smk"
include: "rules/download/osm.smk"
include: "rules/download/land_cover.smk"

include: "rules/preprocess/gadm.smk"
include: "rules/preprocess/filter_osm_data.smk"
include: "rules/preprocess/trim_hazard_data.smk"
include: "rules/preprocess/create_bbox_extracts.smk"
include: "rules/preprocess/slice.smk"
include: "rules/preprocess/join_network.smk"
include: "rules/preprocess/targets.smk"
include: "rules/preprocess/create_network.smk"
include: "rules/preprocess/join_data.smk"
include: "rules/preprocess/osm_to_geoparquet.smk"
include: "rules/preprocess/create_overall_bbox.smk"
include: "rules/preprocess/powerplants.smk"
include: "rules/preprocess/IBTrACS.smk"
include: "rules/preprocess/STORM.smk"
include: "rules/preprocess/IRIS.smk"

include: "rules/exposure/join_data.smk"
include: "rules/exposure/network_raster_intersection.smk"
include: "rules/exposure/wind_fields.smk"
include: "rules/exposure/flood_damages.smk"
include: "rules/exposure/storm_damages.smk"
include: "rules/exposure/aggregate_to_admin_area.smk"

include: "rules/analyse/network_components.smk"
include: "rules/analyse/map/storm_tracks.smk"
include: "rules/analyse/map/outages.smk"
include: "rules/analyse/map/wind_fields.smk"
include: "rules/analyse/plot/target_disruption.smk"
include: "rules/analyse/plot/customers_affected_by_storm.smk"

include: "rules/target/cyclone-grid.smk"

# Remove intermediate directories
rule clean:
    shell:
        """
        rm -rf {config[output_dir]}/json &&
        rm -rf {config[output_dir]}/geoparquet &&
        rm -rf {config[output_dir]}/slices &&
        rm -rf {config[output_dir]}/splits &&
        rm -rf {config[output_dir]}/direct_damages &&
        rm -rf {config[output_dir]}/power/by_country
        """
